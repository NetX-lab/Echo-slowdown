[
    {
        "name": "x",
        "op": "x",
        "input_nodes": [
            "optimizer_zero"
        ],
        "output_nodes": [
            "linear1"
        ],
        "input_types": [],
        "input_shapes": [],
        "output_types": [
            "torch.float32"
        ],
        "output_shapes": [
            [
                1,
                100
            ]
        ]
    },
    {
        "name": "linear1",
        "op": "torch.nn.modules.linear.Linear",
        "input_nodes": [
            "x"
        ],
        "output_nodes": [
            "output"
        ],
        "input_types": [
            "torch.float32"
        ],
        "input_shapes": [
            [
                1,
                100
            ]
        ],
        "output_types": [
            "torch.float32"
        ],
        "output_shapes": [
            [
                1,
                10
            ]
        ],
        "weight_type": "torch.float32",
        "weight_shape": [
            10,
            100
        ],
        "bias_type": "torch.float32",
        "bias_shape": [
            10
        ],
        "attrs": {
            "in_features": 100,
            "out_features": 10
        }
    },
    {
        "name": "output",
        "op": "output",
        "input_nodes": [
            "linear1"
        ],
        "output_nodes": [
            "AddmmBackward00"
        ],
        "input_types": [
            "torch.float32"
        ],
        "input_shapes": [
            [
                1,
                10
            ]
        ],
        "output_types": [
            "torch.float32"
        ],
        "output_shapes": [
            [
                1,
                10
            ]
        ]
    },
    {
        "name": "AddmmBackward00",
        "op": "AddmmBackward0",
        "input_nodes": [
            "output"
        ],
        "output_nodes": [
            "AccumulateGrad0",
            "TBackward00"
        ],
        "input_types": [
            "torch.float32"
        ],
        "input_shapes": [
            [
                1,
                10
            ]
        ],
        "output_types": [
            "torch.float32",
            null,
            "torch.float32"
        ],
        "output_shapes": [
            [
                10
            ],
            null,
            [
                100,
                10
            ]
        ],
        "attrs": {
            "in_features": 100,
            "out_features": 10
        }
    },
    {
        "name": "AccumulateGrad0",
        "op": "AccumulateGrad",
        "input_nodes": [
            "AddmmBackward00"
        ],
        "output_nodes": [
            "ddp_pre_0"
        ],
        "input_types": [
            "torch.float32"
        ],
        "input_shapes": [
            [
                10
            ]
        ],
        "output_types": [],
        "output_shapes": []
    },
    {
        "name": "TBackward00",
        "op": "TBackward0",
        "input_nodes": [
            "AddmmBackward00"
        ],
        "output_nodes": [
            "AccumulateGrad1"
        ],
        "input_types": [
            "torch.float32"
        ],
        "input_shapes": [
            [
                100,
                10
            ]
        ],
        "output_types": [
            "torch.float32"
        ],
        "output_shapes": [
            [
                10,
                100
            ]
        ]
    },
    {
        "name": "AccumulateGrad1",
        "op": "AccumulateGrad",
        "input_nodes": [
            "TBackward00"
        ],
        "output_nodes": [
            "ddp_pre_0"
        ],
        "input_types": [
            "torch.float32"
        ],
        "input_shapes": [
            [
                10,
                100
            ]
        ],
        "output_types": [],
        "output_shapes": []
    },
    {
        "name": "ddp_pre_0",
        "op": "ddp_pre",
        "input_nodes": [
            "AccumulateGrad0",
            "AccumulateGrad1"
        ],
        "output_nodes": [
            "ddp_Allreduce_0"
        ],
        "input_types": [],
        "input_shapes": [],
        "output_types": [],
        "output_shapes": [],
        "attrs": {
            "bucket_size": 1010
        }
    },
    {
        "name": "ddp_Allreduce_0",
        "op": "ddp_Allreduce",
        "input_nodes": [
            "ddp_pre_0"
        ],
        "output_nodes": [
            "optimizer_step"
        ],
        "input_types": [],
        "input_shapes": [],
        "output_types": [],
        "output_shapes": [],
        "attrs": {
            "bucket_size": 1010
        }
    },
    {
        "name": "optimizer_zero",
        "op": "optimizer_zero",
        "input_nodes": [],
        "output_nodes": [
            "x"
        ],
        "input_types": [
            "torch.float32",
            "torch.float32"
        ],
        "input_shapes": [
            [
                10,
                100
            ],
            [
                10
            ]
        ],
        "output_types": [],
        "output_shapes": [],
        "attrs": {
            "lr": 0.01,
            "momentum": 0,
            "dampening": 0,
            "weight_decay": 0,
            "nesterov": false,
            "maximize": false,
            "foreach": null,
            "differentiable": false
        }
    },
    {
        "name": "optimizer_step",
        "op": "optimizer_step",
        "input_nodes": [
            "ddp_Allreduce_0"
        ],
        "output_nodes": [],
        "input_types": [
            "torch.float32",
            "torch.float32"
        ],
        "input_shapes": [
            [
                10,
                100
            ],
            [
                10
            ]
        ],
        "output_types": [],
        "output_shapes": [],
        "attrs": {
            "lr": 0.01,
            "momentum": 0,
            "dampening": 0,
            "weight_decay": 0,
            "nesterov": false,
            "maximize": false,
            "foreach": null,
            "differentiable": false
        }
    }
]